{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/envs/venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.2.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1304 sha256=9ea6719ad20f270d5de53f09c80a5712914ef6fe093bf122f72687cd237bd7cd\n",
      "  Stored in directory: /opt/ml/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-1.1.3 sklearn-0.0 threadpoolctl-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoModel\n",
    "!pip install sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold , KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37me9164cf4a246           \u001b[m  Tue Nov  1 06:35:05 2022  \u001b[1m\u001b[30m450.80.02\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTesla V100-PCIE-32GB\u001b[m |\u001b[31m 38°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2319\u001b[m / \u001b[33m32510\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train.csv')\n",
    "val_data = pd.read_csv('../data/dev.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9324\n",
      "550\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'total_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(train_data))\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(val_data))\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(total_data))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def prepare_input(self,text):\n",
    "        inputs = self.tokenizer.encode_plus(text, return_tensors=None, add_special_tokens=True, padding = 'max_length',truncation=True)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = torch.tensor(v, dtype=torch.long) # 텐서로 변환\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained('klue/roberta-small', max_length=160) \n",
    "        self.texts = (data['sentence_1'] + '[SEP]' + data['sentence_2']).values\n",
    "        if 'label' in data.columns:\n",
    "            self.targets = data['label'].values\n",
    "        else:\n",
    "            self.targets = []\n",
    "\n",
    "    def prepare_input(self,text):\n",
    "        inputs = self.tokenizer.encode(text, return_tensors=None,\n",
    "        add_special_tokens=True, padding = 'max_length',truncation=True)\n",
    "        # for k, v in inputs.items():\n",
    "        #     inputs[k] = torch.tensor(v, dtype=torch.long) # 텐서로 변환\n",
    "        return inputs\n",
    "\n",
    "    # 학습 및 추론 과정에서 데이터를 1개씩 꺼내오는 곳\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.prepare_input(self.texts[idx])\n",
    "        # 정답이 있다면 else문을, 없다면 if문을 수행합니다\n",
    "        if len(self.targets) == 0:\n",
    "            return inputs\n",
    "        else:\n",
    "            label = torch.tensor(self.targets[idx],dtype=torch.float)\n",
    "            return inputs, label\n",
    "\n",
    "    # 입력하는 개수만큼 데이터를 사용합니다\n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>binary-label</th>\n",
       "      <th>simple_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boostcamp-sts-v1-train-000</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~</td>\n",
       "      <td>반전도 있고,사랑도 있고재미도있네요.</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boostcamp-sts-v1-train-001</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>앗 제가 접근권한이 없다고 뜹니다;;</td>\n",
       "      <td>오, 액세스 권한이 없다고 합니다.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boostcamp-sts-v1-train-002</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>주택청약조건 변경해주세요.</td>\n",
       "      <td>주택청약 무주택기준 변경해주세요.</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boostcamp-sts-v1-train-003</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>입사후 처음 대면으로 만나 반가웠습니다.</td>\n",
       "      <td>화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boostcamp-sts-v1-train-004</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>뿌듯뿌듯 하네요!!</td>\n",
       "      <td>꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>boostcamp-sts-v1-dev-545</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>사회적 이슈를 다루고 있는 가슴 찡한 드라마네요,,,</td>\n",
       "      <td>정말 가슴을 따뜻하게 한 좋은 드라마...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>boostcamp-sts-v1-dev-546</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>(비타민 먹는 장면)</td>\n",
       "      <td>(비타민을 먹는 장면)</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>boostcamp-sts-v1-dev-547</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>내용이 뭔 내용인지도 모르겠음</td>\n",
       "      <td>무슨의미로 만들었는지 모르겠음..</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>boostcamp-sts-v1-dev-548</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>(예: 주말에는 개인캘린더만, 업무시간에는 업무 캘린더만 보기)</td>\n",
       "      <td>(예: 주말에는 개인캘린더만 보고, 업무시간에는 업무캘린더만 보기)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>boostcamp-sts-v1-dev-549</td>\n",
       "      <td>nsmc-rtt</td>\n",
       "      <td>다소 허접한 영상도 군데군데 있음.</td>\n",
       "      <td>엉뚱한 영상도 몇 개 있습니다.</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9874 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id            source  \\\n",
       "0    boostcamp-sts-v1-train-000      nsmc-sampled   \n",
       "1    boostcamp-sts-v1-train-001         slack-rtt   \n",
       "2    boostcamp-sts-v1-train-002  petition-sampled   \n",
       "3    boostcamp-sts-v1-train-003     slack-sampled   \n",
       "4    boostcamp-sts-v1-train-004     slack-sampled   \n",
       "..                          ...               ...   \n",
       "545    boostcamp-sts-v1-dev-545      nsmc-sampled   \n",
       "546    boostcamp-sts-v1-dev-546         slack-rtt   \n",
       "547    boostcamp-sts-v1-dev-547      nsmc-sampled   \n",
       "548    boostcamp-sts-v1-dev-548         slack-rtt   \n",
       "549    boostcamp-sts-v1-dev-549          nsmc-rtt   \n",
       "\n",
       "                                 sentence_1  \\\n",
       "0    스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~   \n",
       "1                      앗 제가 접근권한이 없다고 뜹니다;;   \n",
       "2                            주택청약조건 변경해주세요.   \n",
       "3                    입사후 처음 대면으로 만나 반가웠습니다.   \n",
       "4                                뿌듯뿌듯 하네요!!   \n",
       "..                                      ...   \n",
       "545           사회적 이슈를 다루고 있는 가슴 찡한 드라마네요,,,   \n",
       "546                             (비타민 먹는 장면)   \n",
       "547                        내용이 뭔 내용인지도 모르겠음   \n",
       "548     (예: 주말에는 개인캘린더만, 업무시간에는 업무 캘린더만 보기)   \n",
       "549                     다소 허접한 영상도 군데군데 있음.   \n",
       "\n",
       "                                sentence_2  label  binary-label  simple_label  \n",
       "0                     반전도 있고,사랑도 있고재미도있네요.    2.2           0.0             2  \n",
       "1                      오, 액세스 권한이 없다고 합니다.    4.2           1.0             4  \n",
       "2                       주택청약 무주택기준 변경해주세요.    2.4           0.0             2  \n",
       "3             화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.    3.0           1.0             3  \n",
       "4                    꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!    0.0           0.0             0  \n",
       "..                                     ...    ...           ...           ...  \n",
       "545                정말 가슴을 따뜻하게 한 좋은 드라마...    2.0           0.0             2  \n",
       "546                           (비타민을 먹는 장면)    4.8           1.0             4  \n",
       "547                     무슨의미로 만들었는지 모르겠음..    2.4           0.0             2  \n",
       "548  (예: 주말에는 개인캘린더만 보고, 업무시간에는 업무캘린더만 보기)    5.0           1.0             5  \n",
       "549                      엉뚱한 영상도 몇 개 있습니다.    2.2           0.0             2  \n",
       "\n",
       "[9874 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = pd.concat([train_data,val_data],axis = 0)\n",
    "total_data['simple_label'] = total_data['label'].apply(lambda x : int(x))\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = total_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>binary-label</th>\n",
       "      <th>simple_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boostcamp-sts-v1-train-000</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~</td>\n",
       "      <td>반전도 있고,사랑도 있고재미도있네요.</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boostcamp-sts-v1-train-001</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>앗 제가 접근권한이 없다고 뜹니다;;</td>\n",
       "      <td>오, 액세스 권한이 없다고 합니다.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boostcamp-sts-v1-train-002</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>주택청약조건 변경해주세요.</td>\n",
       "      <td>주택청약 무주택기준 변경해주세요.</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boostcamp-sts-v1-train-003</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>입사후 처음 대면으로 만나 반가웠습니다.</td>\n",
       "      <td>화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boostcamp-sts-v1-train-004</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>뿌듯뿌듯 하네요!!</td>\n",
       "      <td>꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>boostcamp-sts-v1-dev-545</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>사회적 이슈를 다루고 있는 가슴 찡한 드라마네요,,,</td>\n",
       "      <td>정말 가슴을 따뜻하게 한 좋은 드라마...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>boostcamp-sts-v1-dev-546</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>(비타민 먹는 장면)</td>\n",
       "      <td>(비타민을 먹는 장면)</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>boostcamp-sts-v1-dev-547</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>내용이 뭔 내용인지도 모르겠음</td>\n",
       "      <td>무슨의미로 만들었는지 모르겠음..</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>boostcamp-sts-v1-dev-548</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>(예: 주말에는 개인캘린더만, 업무시간에는 업무 캘린더만 보기)</td>\n",
       "      <td>(예: 주말에는 개인캘린더만 보고, 업무시간에는 업무캘린더만 보기)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>boostcamp-sts-v1-dev-549</td>\n",
       "      <td>nsmc-rtt</td>\n",
       "      <td>다소 허접한 영상도 군데군데 있음.</td>\n",
       "      <td>엉뚱한 영상도 몇 개 있습니다.</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9874 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id            source  \\\n",
       "0     boostcamp-sts-v1-train-000      nsmc-sampled   \n",
       "1     boostcamp-sts-v1-train-001         slack-rtt   \n",
       "2     boostcamp-sts-v1-train-002  petition-sampled   \n",
       "3     boostcamp-sts-v1-train-003     slack-sampled   \n",
       "4     boostcamp-sts-v1-train-004     slack-sampled   \n",
       "...                          ...               ...   \n",
       "9869    boostcamp-sts-v1-dev-545      nsmc-sampled   \n",
       "9870    boostcamp-sts-v1-dev-546         slack-rtt   \n",
       "9871    boostcamp-sts-v1-dev-547      nsmc-sampled   \n",
       "9872    boostcamp-sts-v1-dev-548         slack-rtt   \n",
       "9873    boostcamp-sts-v1-dev-549          nsmc-rtt   \n",
       "\n",
       "                                  sentence_1  \\\n",
       "0     스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~   \n",
       "1                       앗 제가 접근권한이 없다고 뜹니다;;   \n",
       "2                             주택청약조건 변경해주세요.   \n",
       "3                     입사후 처음 대면으로 만나 반가웠습니다.   \n",
       "4                                 뿌듯뿌듯 하네요!!   \n",
       "...                                      ...   \n",
       "9869           사회적 이슈를 다루고 있는 가슴 찡한 드라마네요,,,   \n",
       "9870                             (비타민 먹는 장면)   \n",
       "9871                        내용이 뭔 내용인지도 모르겠음   \n",
       "9872     (예: 주말에는 개인캘린더만, 업무시간에는 업무 캘린더만 보기)   \n",
       "9873                     다소 허접한 영상도 군데군데 있음.   \n",
       "\n",
       "                                 sentence_2  label  binary-label  simple_label  \n",
       "0                      반전도 있고,사랑도 있고재미도있네요.    2.2           0.0             2  \n",
       "1                       오, 액세스 권한이 없다고 합니다.    4.2           1.0             4  \n",
       "2                        주택청약 무주택기준 변경해주세요.    2.4           0.0             2  \n",
       "3              화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.    3.0           1.0             3  \n",
       "4                     꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!    0.0           0.0             0  \n",
       "...                                     ...    ...           ...           ...  \n",
       "9869                정말 가슴을 따뜻하게 한 좋은 드라마...    2.0           0.0             2  \n",
       "9870                           (비타민을 먹는 장면)    4.8           1.0             4  \n",
       "9871                     무슨의미로 만들었는지 모르겠음..    2.4           0.0             2  \n",
       "9872  (예: 주말에는 개인캘린더만 보고, 업무시간에는 업무캘린더만 보기)    5.0           1.0             5  \n",
       "9873                      엉뚱한 영상도 몇 개 있습니다.    2.2           0.0             2  \n",
       "\n",
       "[9874 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>binary-label</th>\n",
       "      <th>simple_label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boostcamp-sts-v1-train-000</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~</td>\n",
       "      <td>반전도 있고,사랑도 있고재미도있네요.</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boostcamp-sts-v1-train-001</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>앗 제가 접근권한이 없다고 뜹니다;;</td>\n",
       "      <td>오, 액세스 권한이 없다고 합니다.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boostcamp-sts-v1-train-002</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>주택청약조건 변경해주세요.</td>\n",
       "      <td>주택청약 무주택기준 변경해주세요.</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boostcamp-sts-v1-train-003</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>입사후 처음 대면으로 만나 반가웠습니다.</td>\n",
       "      <td>화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boostcamp-sts-v1-train-004</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>뿌듯뿌듯 하네요!!</td>\n",
       "      <td>꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>boostcamp-sts-v1-dev-545</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>사회적 이슈를 다루고 있는 가슴 찡한 드라마네요,,,</td>\n",
       "      <td>정말 가슴을 따뜻하게 한 좋은 드라마...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>boostcamp-sts-v1-dev-546</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>(비타민 먹는 장면)</td>\n",
       "      <td>(비타민을 먹는 장면)</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>boostcamp-sts-v1-dev-547</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>내용이 뭔 내용인지도 모르겠음</td>\n",
       "      <td>무슨의미로 만들었는지 모르겠음..</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>boostcamp-sts-v1-dev-548</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>(예: 주말에는 개인캘린더만, 업무시간에는 업무 캘린더만 보기)</td>\n",
       "      <td>(예: 주말에는 개인캘린더만 보고, 업무시간에는 업무캘린더만 보기)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>boostcamp-sts-v1-dev-549</td>\n",
       "      <td>nsmc-rtt</td>\n",
       "      <td>다소 허접한 영상도 군데군데 있음.</td>\n",
       "      <td>엉뚱한 영상도 몇 개 있습니다.</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9874 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id            source  \\\n",
       "0     boostcamp-sts-v1-train-000      nsmc-sampled   \n",
       "1     boostcamp-sts-v1-train-001         slack-rtt   \n",
       "2     boostcamp-sts-v1-train-002  petition-sampled   \n",
       "3     boostcamp-sts-v1-train-003     slack-sampled   \n",
       "4     boostcamp-sts-v1-train-004     slack-sampled   \n",
       "...                          ...               ...   \n",
       "9869    boostcamp-sts-v1-dev-545      nsmc-sampled   \n",
       "9870    boostcamp-sts-v1-dev-546         slack-rtt   \n",
       "9871    boostcamp-sts-v1-dev-547      nsmc-sampled   \n",
       "9872    boostcamp-sts-v1-dev-548         slack-rtt   \n",
       "9873    boostcamp-sts-v1-dev-549          nsmc-rtt   \n",
       "\n",
       "                                  sentence_1  \\\n",
       "0     스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~   \n",
       "1                       앗 제가 접근권한이 없다고 뜹니다;;   \n",
       "2                             주택청약조건 변경해주세요.   \n",
       "3                     입사후 처음 대면으로 만나 반가웠습니다.   \n",
       "4                                 뿌듯뿌듯 하네요!!   \n",
       "...                                      ...   \n",
       "9869           사회적 이슈를 다루고 있는 가슴 찡한 드라마네요,,,   \n",
       "9870                             (비타민 먹는 장면)   \n",
       "9871                        내용이 뭔 내용인지도 모르겠음   \n",
       "9872     (예: 주말에는 개인캘린더만, 업무시간에는 업무 캘린더만 보기)   \n",
       "9873                     다소 허접한 영상도 군데군데 있음.   \n",
       "\n",
       "                                 sentence_2  label  binary-label  \\\n",
       "0                      반전도 있고,사랑도 있고재미도있네요.    2.2           0.0   \n",
       "1                       오, 액세스 권한이 없다고 합니다.    4.2           1.0   \n",
       "2                        주택청약 무주택기준 변경해주세요.    2.4           0.0   \n",
       "3              화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.    3.0           1.0   \n",
       "4                     꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!    0.0           0.0   \n",
       "...                                     ...    ...           ...   \n",
       "9869                정말 가슴을 따뜻하게 한 좋은 드라마...    2.0           0.0   \n",
       "9870                           (비타민을 먹는 장면)    4.8           1.0   \n",
       "9871                     무슨의미로 만들었는지 모르겠음..    2.4           0.0   \n",
       "9872  (예: 주말에는 개인캘린더만 보고, 업무시간에는 업무캘린더만 보기)    5.0           1.0   \n",
       "9873                      엉뚱한 영상도 몇 개 있습니다.    2.2           0.0   \n",
       "\n",
       "      simple_label  fold  \n",
       "0                2   2.0  \n",
       "1                4   4.0  \n",
       "2                2   3.0  \n",
       "3                3   4.0  \n",
       "4                0   4.0  \n",
       "...            ...   ...  \n",
       "9869             2   3.0  \n",
       "9870             4   4.0  \n",
       "9871             2   0.0  \n",
       "9872             5   1.0  \n",
       "9873             2   3.0  \n",
       "\n",
       "[9874 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle = True, random_state=22)\n",
    "for n_fold, (_,v_idx) in enumerate(skf.split(total_data,total_data['simple_label'])):\n",
    "    total_data.loc[v_idx,'fold'] = n_fold\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = total_data[total_data['fold'] != 0]\n",
    "val_data = total_data[total_data['fold'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3039\n",
       "3    1460\n",
       "1    1182\n",
       "4    1130\n",
       "2     997\n",
       "5      91\n",
       "Name: simple_label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['simple_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    760\n",
       "3    365\n",
       "1    296\n",
       "4    282\n",
       "2    250\n",
       "5     22\n",
       "Name: simple_label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data['simple_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "petition-sampled    2015\n",
       "nsmc-sampled        1910\n",
       "slack-sampled       1687\n",
       "slack-rtt            909\n",
       "petition-rtt         713\n",
       "nsmc-rtt             665\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source            simple_label\n",
       "slack-sampled     0               1053\n",
       "petition-sampled  0                960\n",
       "nsmc-sampled      0                916\n",
       "                  1                398\n",
       "slack-rtt         3                376\n",
       "petition-sampled  1                364\n",
       "petition-rtt      4                334\n",
       "slack-rtt         4                316\n",
       "nsmc-sampled      2                311\n",
       "slack-sampled     1                305\n",
       "nsmc-rtt          3                300\n",
       "petition-sampled  3                248\n",
       "                  2                240\n",
       "petition-rtt      3                216\n",
       "nsmc-sampled      3                213\n",
       "nsmc-rtt          4                202\n",
       "slack-sampled     2                167\n",
       "petition-sampled  4                164\n",
       "slack-rtt         2                117\n",
       "slack-sampled     3                107\n",
       "nsmc-rtt          2                 91\n",
       "petition-rtt      2                 71\n",
       "nsmc-sampled      4                 70\n",
       "slack-rtt         1                 52\n",
       "slack-sampled     4                 44\n",
       "slack-rtt         0                 44\n",
       "petition-sampled  5                 39\n",
       "nsmc-rtt          0                 38\n",
       "petition-rtt      1                 33\n",
       "                  5                 31\n",
       "nsmc-rtt          1                 30\n",
       "petition-rtt      0                 28\n",
       "slack-sampled     5                 11\n",
       "slack-rtt         5                  4\n",
       "nsmc-rtt          5                  4\n",
       "nsmc-sampled      5                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[['source','simple_label']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.duplicated(['sentence_1', 'sentence_2']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "  Using cached tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/venv/lib/python3.8/site-packages (from tensorboardX) (1.19.5)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /opt/conda/envs/venv/lib/python3.8/site-packages (from tensorboardX) (3.20.1)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX\n",
    "from pororo import Pororo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pororo import Pororo\n",
    "mt = Pororo(task='translation', lang = 'multi')\n",
    "\n",
    "def back_trans_pororo(text,lang='en'):\n",
    "    text_to_lang = mt(text, src='ko', tgt=lang)\n",
    "    new_text = mt(text_to_lang,src=lang,tgt='ko')\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = Pororo(task='translation', lang = 'multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please build (or rebuild) Cython components with `python setup.py build_ext --inplace`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/fairseq/data/data_utils.py:312\u001b[0m, in \u001b[0;36mbatch_by_size\u001b[0;34m(indices, num_tokens_fn, num_tokens_vec, max_tokens, max_sentences, required_batch_size_multiple, fixed_shapes)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mfairseq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_utils_fast\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    313\u001b[0m         batch_by_size_fn,\n\u001b[1;32m    314\u001b[0m         batch_by_size_vec,\n\u001b[1;32m    315\u001b[0m         batch_fixed_shapes_fast,\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    317\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[0;32mfairseq/data/data_utils_fast.pyx:1\u001b[0m, in \u001b[0;36minit fairseq.data.data_utils_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/data/EDA/pre.ipynb 셀 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baistage/opt/ml/data/EDA/pre.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m mt(\u001b[39m'\u001b[39;49m\u001b[39mhello\u001b[39;49m\u001b[39m'\u001b[39;49m, src\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m'\u001b[39;49m, tgt\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mko\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/pororo/tasks/machine_translation.py:334\u001b[0m, in \u001b[0;36mPororoTransformerTransMulti.__call__\u001b[0;34m(self, text, src, tgt, beam, temperature, top_k, top_p, no_repeat_ngram_size, len_penalty)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39massert\u001b[39;00m src \u001b[39min\u001b[39;00m [\n\u001b[1;32m    321\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mko\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    322\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mzh\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    323\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mja\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    324\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    325\u001b[0m ], \u001b[39m\"\u001b[39m\u001b[39mSource language must be one of CJKE !\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m \u001b[39massert\u001b[39;00m tgt \u001b[39min\u001b[39;00m [\n\u001b[1;32m    328\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mko\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    329\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mzh\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    330\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mja\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    331\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    332\u001b[0m ], \u001b[39m\"\u001b[39m\u001b[39mTarget language must be one of CJKE !\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 334\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\n\u001b[1;32m    335\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m    336\u001b[0m         t,\n\u001b[1;32m    337\u001b[0m         src,\n\u001b[1;32m    338\u001b[0m         tgt,\n\u001b[1;32m    339\u001b[0m         beam,\n\u001b[1;32m    340\u001b[0m         temperature,\n\u001b[1;32m    341\u001b[0m         top_k,\n\u001b[1;32m    342\u001b[0m         top_p,\n\u001b[1;32m    343\u001b[0m         no_repeat_ngram_size,\n\u001b[1;32m    344\u001b[0m         len_penalty,\n\u001b[1;32m    345\u001b[0m     ) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sent_tokenizer(text, src)\n\u001b[1;32m    346\u001b[0m ])\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/pororo/tasks/machine_translation.py:335\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39massert\u001b[39;00m src \u001b[39min\u001b[39;00m [\n\u001b[1;32m    321\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mko\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    322\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mzh\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    323\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mja\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    324\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    325\u001b[0m ], \u001b[39m\"\u001b[39m\u001b[39mSource language must be one of CJKE !\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m \u001b[39massert\u001b[39;00m tgt \u001b[39min\u001b[39;00m [\n\u001b[1;32m    328\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mko\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    329\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mzh\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    330\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mja\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    331\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    332\u001b[0m ], \u001b[39m\"\u001b[39m\u001b[39mTarget language must be one of CJKE !\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\n\u001b[0;32m--> 335\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m    336\u001b[0m         t,\n\u001b[1;32m    337\u001b[0m         src,\n\u001b[1;32m    338\u001b[0m         tgt,\n\u001b[1;32m    339\u001b[0m         beam,\n\u001b[1;32m    340\u001b[0m         temperature,\n\u001b[1;32m    341\u001b[0m         top_k,\n\u001b[1;32m    342\u001b[0m         top_p,\n\u001b[1;32m    343\u001b[0m         no_repeat_ngram_size,\n\u001b[1;32m    344\u001b[0m         len_penalty,\n\u001b[1;32m    345\u001b[0m     ) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sent_tokenizer(text, src)\n\u001b[1;32m    346\u001b[0m ])\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/pororo/tasks/machine_translation.py:291\u001b[0m, in \u001b[0;36mPororoTransformerTransMulti.predict\u001b[0;34m(self, text, src, tgt, beam, temperature, top_k, top_p, no_repeat_ngram_size, len_penalty, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m top_k \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m top_p \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m    289\u001b[0m     sampling \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mtranslate(\n\u001b[1;32m    292\u001b[0m     text,\n\u001b[1;32m    293\u001b[0m     beam\u001b[39m=\u001b[39;49mbeam,\n\u001b[1;32m    294\u001b[0m     sampling\u001b[39m=\u001b[39;49msampling,\n\u001b[1;32m    295\u001b[0m     temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[1;32m    296\u001b[0m     sampling_topk\u001b[39m=\u001b[39;49mtop_k,\n\u001b[1;32m    297\u001b[0m     sampling_topp\u001b[39m=\u001b[39;49mtop_p,\n\u001b[1;32m    298\u001b[0m     max_len_a\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    299\u001b[0m     max_len_b\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m    300\u001b[0m     no_repeat_ngram_size\u001b[39m=\u001b[39;49mno_repeat_ngram_size,\n\u001b[1;32m    301\u001b[0m     lenpen\u001b[39m=\u001b[39;49mlen_penalty,\n\u001b[1;32m    302\u001b[0m )\n\u001b[1;32m    303\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_postprocess(output)\n\u001b[1;32m    304\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/fairseq/hub_utils.py:124\u001b[0m, in \u001b[0;36mGeneratorHubInterface.translate\u001b[0;34m(self, sentences, beam, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslate\u001b[39m(\n\u001b[1;32m    122\u001b[0m     \u001b[39mself\u001b[39m, sentences: List[\u001b[39mstr\u001b[39m], beam: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    123\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample(sentences, beam, verbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/fairseq/hub_utils.py:130\u001b[0m, in \u001b[0;36mGeneratorHubInterface.sample\u001b[0;34m(self, sentences, beam, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample\u001b[39m(\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m, sentences: List[\u001b[39mstr\u001b[39m], beam: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    128\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m    129\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(sentences, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample([sentences], beam\u001b[39m=\u001b[39;49mbeam, verbose\u001b[39m=\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    131\u001b[0m     tokenized_sentences \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode(sentence) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences]\n\u001b[1;32m    132\u001b[0m     batched_hypos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(tokenized_sentences, beam, verbose, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/fairseq/hub_utils.py:132\u001b[0m, in \u001b[0;36mGeneratorHubInterface.sample\u001b[0;34m(self, sentences, beam, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample([sentences], beam\u001b[39m=\u001b[39mbeam, verbose\u001b[39m=\u001b[39mverbose, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    131\u001b[0m tokenized_sentences \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode(sentence) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences]\n\u001b[0;32m--> 132\u001b[0m batched_hypos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(tokenized_sentences, beam, verbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(hypos[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtokens\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mfor\u001b[39;00m hypos \u001b[39min\u001b[39;00m batched_hypos]\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/fairseq/hub_utils.py:187\u001b[0m, in \u001b[0;36mGeneratorHubInterface.generate\u001b[0;34m(self, tokenized_sentences, beam, verbose, skip_invalid_size_inputs, inference_step_args, prefix_allowed_tokens_fn, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m inference_step_args \u001b[39m=\u001b[39m inference_step_args \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    186\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 187\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_batches(tokenized_sentences, skip_invalid_size_inputs):\n\u001b[1;32m    188\u001b[0m     batch \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mapply_to_sample(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), batch)\n\u001b[1;32m    189\u001b[0m     translations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39minference_step(\n\u001b[1;32m    190\u001b[0m         generator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels, batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minference_step_args\n\u001b[1;32m    191\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/fairseq/hub_utils.py:274\u001b[0m, in \u001b[0;36mGeneratorHubInterface._build_batches\u001b[0;34m(self, tokens, skip_invalid_size_inputs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_batches\u001b[39m(\n\u001b[1;32m    271\u001b[0m     \u001b[39mself\u001b[39m, tokens: List[List[\u001b[39mint\u001b[39m]], skip_invalid_size_inputs: \u001b[39mbool\u001b[39m\n\u001b[1;32m    272\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Dict[\u001b[39mstr\u001b[39m, Any]]:\n\u001b[1;32m    273\u001b[0m     lengths \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor([t\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tokens])\n\u001b[0;32m--> 274\u001b[0m     batch_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask\u001b[39m.\u001b[39;49mget_batch_iterator(\n\u001b[1;32m    275\u001b[0m         dataset\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask\u001b[39m.\u001b[39;49mbuild_dataset_for_inference(tokens, lengths),\n\u001b[1;32m    276\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mmax_tokens,\n\u001b[1;32m    277\u001b[0m         max_sentences\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[1;32m    278\u001b[0m         max_positions\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_positions,\n\u001b[1;32m    279\u001b[0m         ignore_invalid_inputs\u001b[39m=\u001b[39;49mskip_invalid_size_inputs,\n\u001b[1;32m    280\u001b[0m         disable_iterator_cache\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    281\u001b[0m     )\u001b[39m.\u001b[39mnext_epoch_itr(shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    282\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_iterator\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/fairseq/tasks/fairseq_task.py:295\u001b[0m, in \u001b[0;36mFairseqTask.get_batch_iterator\u001b[0;34m(self, dataset, max_tokens, max_sentences, max_positions, ignore_invalid_inputs, required_batch_size_multiple, seed, num_shards, shard_id, num_workers, epoch, data_buffer_size, disable_iterator_cache, skip_remainder_batch, grouped_shuffling, update_epoch_batch_itr)\u001b[0m\n\u001b[1;32m    290\u001b[0m     indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_indices_by_size(\n\u001b[1;32m    291\u001b[0m         indices, dataset, max_positions, ignore_invalid_inputs\n\u001b[1;32m    292\u001b[0m     )\n\u001b[1;32m    294\u001b[0m \u001b[39m# create mini-batches with given size constraints\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m batch_sampler \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mbatch_by_size(\n\u001b[1;32m    296\u001b[0m     indices,\n\u001b[1;32m    297\u001b[0m     max_tokens\u001b[39m=\u001b[39;49mmax_tokens,\n\u001b[1;32m    298\u001b[0m     max_sentences\u001b[39m=\u001b[39;49mmax_sentences,\n\u001b[1;32m    299\u001b[0m     required_batch_size_multiple\u001b[39m=\u001b[39;49mrequired_batch_size_multiple,\n\u001b[1;32m    300\u001b[0m )\n\u001b[1;32m    302\u001b[0m reuse_dataloader \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg, \u001b[39m\"\u001b[39m\u001b[39mreuse_dataloader\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    304\u001b[0m \u001b[39m# return a reusable, sharded iterator\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/fairseq/data/fairseq_dataset.py:145\u001b[0m, in \u001b[0;36mFairseqDataset.batch_by_size\u001b[0;34m(self, indices, max_tokens, max_sentences, required_batch_size_multiple)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     num_tokens_vec \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m \u001b[39mreturn\u001b[39;00m data_utils\u001b[39m.\u001b[39;49mbatch_by_size(\n\u001b[1;32m    146\u001b[0m     indices,\n\u001b[1;32m    147\u001b[0m     num_tokens_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_tokens,\n\u001b[1;32m    148\u001b[0m     num_tokens_vec\u001b[39m=\u001b[39;49mnum_tokens_vec,\n\u001b[1;32m    149\u001b[0m     max_tokens\u001b[39m=\u001b[39;49mmax_tokens,\n\u001b[1;32m    150\u001b[0m     max_sentences\u001b[39m=\u001b[39;49mmax_sentences,\n\u001b[1;32m    151\u001b[0m     required_batch_size_multiple\u001b[39m=\u001b[39;49mrequired_batch_size_multiple,\n\u001b[1;32m    152\u001b[0m     fixed_shapes\u001b[39m=\u001b[39;49mfixed_shapes,\n\u001b[1;32m    153\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/venv/lib/python3.8/site-packages/fairseq/data/data_utils.py:323\u001b[0m, in \u001b[0;36mbatch_by_size\u001b[0;34m(indices, num_tokens_fn, num_tokens_vec, max_tokens, max_sentences, required_batch_size_multiple, fixed_shapes)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease build Cython components with: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`python setup.py build_ext --inplace`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m     )\n\u001b[1;32m    322\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 323\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    324\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease build (or rebuild) Cython components with `python setup.py build_ext --inplace`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    325\u001b[0m     )\n\u001b[1;32m    327\u001b[0m \u001b[39m# added int() to avoid TypeError: an integer is required\u001b[39;00m\n\u001b[1;32m    328\u001b[0m max_tokens \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(max_tokens) \u001b[39mif\u001b[39;00m max_tokens \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Please build (or rebuild) Cython components with `python setup.py build_ext --inplace`."
     ]
    }
   ],
   "source": [
    "mt('hello', src='en', tgt='ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Available tasks are ['mrc', 'rc', 'qa', 'question_answering', 'machine_reading_comprehension', 'reading_comprehension', 'sentiment', 'sentiment_analysis', 'nli', 'natural_language_inference', 'inference', 'fill', 'fill_in_blank', 'fib', 'para', 'pi', 'cse', 'contextual_subword_embedding', 'similarity', 'sts', 'semantic_textual_similarity', 'sentence_similarity', 'sentvec', 'sentence_embedding', 'sentence_vector', 'se', 'inflection', 'morphological_inflection', 'g2p', 'grapheme_to_phoneme', 'grapheme_to_phoneme_conversion', 'w2v', 'wordvec', 'word2vec', 'word_vector', 'word_embedding', 'tokenize', 'tokenise', 'tokenization', 'tokenisation', 'tok', 'segmentation', 'seg', 'mt', 'machine_translation', 'translation', 'pos', 'tag', 'pos_tagging', 'tagging', 'const', 'constituency', 'constituency_parsing', 'cp', 'pg', 'collocation', 'collocate', 'col', 'word_translation', 'wt', 'summarization', 'summarisation', 'text_summarization', 'text_summarisation', 'summary', 'gec', 'review', 'review_scoring', 'lemmatization', 'lemmatisation', 'lemma', 'ner', 'named_entity_recognition', 'entity_recognition', 'zero-topic', 'dp', 'dep_parse', 'caption', 'captioning', 'asr', 'speech_recognition', 'st', 'speech_translation', 'tts', 'text_to_speech', 'speech_synthesis', 'ocr', 'srl', 'semantic_role_labeling', 'p2g', 'aes', 'essay', 'qg', 'question_generation', 'age_suitability', 'wsd']\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pororo.available_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec5511c57591959bfe383097d4c77eeb724c9a6ac951d9eef9284c9544b2033b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
